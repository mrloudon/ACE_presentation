{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\" alt=\"Jupyter\">\n",
    "<h2 style=\"text-align: center;\">What is Jupyter?</h2> \n",
    "\n",
    "## <span style=\"color: #8B6508;\">Ju</span>lia <span style=\"color: #8B6508;\">Pyt</span>hon and <span style=\"color: #8B6508;\">R</span>\n",
    "\n",
    "*\"The Jupyter Notebook is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modelling, machine learning and much more.\"* [(from the Jupyter project homepage)](http://jupyter.org/)\n",
    "\n",
    "A Jupyter notebook consists of a series of cells which can contain formatted text or code. Students\n",
    "can use it as a laboratory notebook in which they document their activities, analyse their data and present their results. In a course like 175.318 Experimental Psychology (or perhaps even a methods course like\n",
    "175\n",
    ".203) a Jupyter notebook could form part of the assessment. \n",
    "\n",
    "Jupyter is based on the **client-server** model, so you interact with it via a web browser. The Jupyter server may be on the same machine as the browser or on a remote machine.\n",
    "\n",
    "Jupyter supports many different programming languages but the main ones are:\n",
    "\n",
    "* **Julia:** Popular for numerical analysis.\n",
    "* **Python:** An interactive, easy to learn general purpose language. Rapidly becoming *the* language for scientific computing.\n",
    "* **R:** A powerful statistical computing and graphics language.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"text-align: center;\">What's so great about Python?</h2>\n",
    "\n",
    "* \"A **C** program is like a fast dance on a newly waxed dance floor by people carrying razors.\" - Waldi Ravens.\n",
    "* \"**C++**: Hard to learn and built to stay that way.\" - anon.\n",
    "* \"**Java** is, in many ways, C++--.\" - Michael Feldman.\n",
    "* \"**Perl** – The only language that looks the same before and after RSA encryption.\" - Keith Bostic.\n",
    "* \"And now for something completely different\" - Monty Python\n",
    "\n",
    "Python is a readable, interactive, high level language (named after Monty Python - not the snake). You can do a lot in only a few lines of code. The really neat thing about Python are the open source libraries (Python calls them packages) that are available for scientific computing. Some particularly useful ones are:\n",
    "\n",
    "* **NumPy:** \"Numerical Python\" This package gives Python a MATLAB-like syntax for handling vectors and matrices. Anyone familiar with MATLAB will be at home with NumPy. MATLAB is great software but a single user license is *NZD$3,350*! [(source)](https://au.mathworks.com/pricing-licensing.html). NumPy is free.\n",
    "\n",
    "* **SciPy:** \"Scientific Python\" Contains *lots* of mathematical functions. In particular, the SciPy package includes a [statistics module](https://docs.scipy.org/doc/scipy-0.18.1/reference/stats.html)\n",
    "(large Python packages are organised into smaller *modules*).\n",
    "\n",
    "* **Matplotlib:** A comprehensive MATLAB-like plotting library capable of producing [publication quality plots](http://matplotlib.org/gallery.html).\n",
    "\n",
    "* **Pandas:** A package of data analysis tools. Pandas lets you import, clean and analyse large data frames.\n",
    "\n",
    "* **PsychoPy:** A psychophysics toolbox written in Python.It is a free alternative to Presentation or E-Prime. It comes with PsychoPy Builder which allows psychophysics experiments to be created with a drag-and-drop interface similar to E-Prime.\n",
    "\n",
    "Python can therefore be used to implement an experiment, reduce the data, perform statistical analyses\n",
    "and present the results. In the past researchers might have used E-Prime to implement the experiment, hack the raw data into shape using Excel and analyse it using SPSS.\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"text-align: center;\">A Quick Taste of Python</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog', 'Pangolin', 'Panamanian Three Toed Sloth']\n"
     ]
    }
   ],
   "source": [
    "# This is a Python code cell. Python ignores lines that start with a '#' \n",
    "\n",
    "# Ok, lets start with a list. Lists are contained in square brackets []. Here we define a list\n",
    "# and assign it to the variable animals:\n",
    "\n",
    "animals = [\"Cat\", \"Dog\", \"Pangolin\", \"Panamanian Three Toed Sloth\"]\n",
    "\n",
    "# print(variable) just prints the contents of the variable to the screen\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve list elements via their index (position) in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pangolin\n"
     ]
    }
   ],
   "source": [
    "print(animals[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python, like most programming languages (except R, sigh...),  starts counting from ** zero **, not one.\n",
    "\n",
    "An instance of a list is technically called an *object*. Objects contain both data and code. A list not only contains\n",
    " items (data) it also comes with a whole bunch of *methods* (code) with which to manipulate its contents. Methods\n",
    "can be accessed using the dot \"**.**\" operator.\n",
    " \n",
    "For example, we can add to our list using the append() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog', 'Pangolin', 'Panamanian Three Toed Sloth', 'Wombat']\n"
     ]
    }
   ],
   "source": [
    "animals.append(\"Wombat\")\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reverse the list using, ummm, reverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wombat', 'Panamanian Three Toed Sloth', 'Pangolin', 'Dog', 'Cat']\n"
     ]
    }
   ],
   "source": [
    "animals.reverse()\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can loop through a list (or other collection) using Python's **for** command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wombat\n",
      "Turnip\n",
      "Panamanian Three Toed Sloth\n",
      "Turnip\n",
      "Pangolin\n",
      "Turnip\n",
      "Dog\n",
      "Turnip\n",
      "Cat\n",
      "Turnip\n"
     ]
    }
   ],
   "source": [
    "for pet in animals:\n",
    "    print(pet)\n",
    "    print(\"Turnip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the clean English like syntax of Python. The ** for ** statement says: \"for element in the collection, process element\". The code within the for loop is indented, this is how Python knows where a block of code begins and ends (other languages commonly use curly braces)\n",
    "\n",
    "For comparison this is what the above looks like in C++ :\n",
    "\n",
    "     std::list<String>::const_iterator iterator;\n",
    "     for (iterator = animals.begin(); iterator != animals.end(); iterator++) {\n",
    "        std::cout << *iterator << std::endl;\n",
    "     }\n",
    "     \n",
    "Lists can contain any kind of data, including other lists. Python's other main data structure is the\n",
    "**dictionary**. Dictionaries are a collection of key-value pairs and are surrounded by curly braces {}.\n",
    "They are rather like records in a database.\n",
    "\n",
    "Keys are restricted to *immutable* data types (strings, numbers, boolean, ...) but values can be anything (including lists and other dictionaries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe\n",
      "['Wombat', 'Panamanian Three Toed Sloth', 'Pangolin', 'Dog', 'Cat']\n"
     ]
    }
   ],
   "source": [
    "person = {\n",
    "    \"first_name\": \"Joe\",\n",
    "    \"last_name\": \"Smith\",\n",
    "    \"pets\": animals\n",
    "}\n",
    "\n",
    "print(person['first_name'])\n",
    "print(person['pets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I used the animals list as a value. Being able to freely nest lists and dictionaries\n",
    "allows arbitrarily complex data structures to be constructed.\n",
    "We can also 'drill' down into the data by chaining keys/indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wombat\n"
     ]
    }
   ],
   "source": [
    "print(person['pets'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"text-align: center;\">A Real Life Example - Analysing EMG Data at Manawatu</h2>\n",
    "\n",
    "The Biopak EMGs used at Albany and Manawatu are effectively multichannel chart recorders - they measure voltage versus time across several channels.\n",
    "\n",
    "<img src=\"face.jpg\" alt=\"Face\" width=\"320\" height=\"260\" style=\"float: right; padding-left: 2em; padding-bottom: 1em;\">\n",
    "\n",
    "In the following example data was recorded from the **zygomaticus** and **corrugator** muscles.\n",
    "\n",
    "As well as the two data channels, eight channels are used for *event marking*. Each time\n",
    "a stimulus appears the event marker channels are briefly pulsed with a pattern of highs and lows identifying what *type* of trial it is. The highs and lows can be considered to be 1's and 0's and can thus be interpreted as a binary number.\n",
    "\n",
    "Below is a screen shot of some raw Biopak data. The two EMG channels are clearly visible at the top (red and blue traces).\n",
    "The eight marker channels are labelled **m_1, m_2, m_4, m_8, m_16, m_32, m_64, m_128** corresponding to their binary position. For example, the first visible event has **m_1**, **m_8** and **m_16** high and the other markers are low so this event type code in decimal is:  ```1 + 8 + 16 = 25```.\n",
    "\n",
    "<div><img src=\"emg_data.png\" alt=\"Face\" width=\"1024\" height=\"768\"></div>\n",
    "\n",
    "One way to analyse EMG data is to measure a *baseline* EMG level just prior to the stimulus (the RMS of 500ms of pre-stimulus data might be typical) then record one or more post-stimulus intervals after a suitable delay (to allow the subject time to react). These post-stimulus measurements can then be normalised by dividing by the baseline (absolute EMG voltages can vary widely for many spurious reasons and are not terribly useful in isolation).\n",
    "\n",
    "The EMG typically samples at 1kHz across 10+ channels so it is easy for a single subject to generate 50-100MB of data. The two data files we are about to analyse are about 70MB each.\n",
    "\n",
    "To automate the process I have written a Python module whose main purpose is to analyse a list of subject files against a *configuration file*. Every experiment is different and requires a configuration file to tell Python what channel is used for what purpose, what the event codes are, what intervals to use, what the sampling rate was, etc. the good news is that we just learned about Python lists and dictionaries and that is how the [configuration file](http://it053760:8888/edit/EMG/config/malc.json) works. \n",
    "\n",
    "---\n",
    "\n",
    "To analyse the data we first need to import the EMG analysis module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EmgException',\n",
       " 'FFT_X_TICKS',\n",
       " 'MAX_CODE',\n",
       " 'MAX_ITERATIONS',\n",
       " 'MAX_TOLERANCE',\n",
       " 'THRESHOLD',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'analyse_data',\n",
       " 'analyse_event',\n",
       " 'analyse_events',\n",
       " 'analyse_file',\n",
       " 'analyse_file_list',\n",
       " 'animation',\n",
       " 'csv',\n",
       " 'datetime',\n",
       " 'describe',\n",
       " 'detect_all_codes',\n",
       " 'detect_all_edges',\n",
       " 'determine_rms',\n",
       " 'fast_detect_edges',\n",
       " 'fft',\n",
       " 'fft_animate',\n",
       " 'fft_hamming',\n",
       " 'fft_plot',\n",
       " 'get_code_edges',\n",
       " 'get_fft_map',\n",
       " 'get_interval',\n",
       " 'io',\n",
       " 'json',\n",
       " 'load_config',\n",
       " 'load_data',\n",
       " 'np',\n",
       " 'os',\n",
       " 'plt',\n",
       " 'pprint',\n",
       " 'process_rms_list',\n",
       " 'progress_callback',\n",
       " 'signal',\n",
       " 'time']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_emg_utils as emg # here I have aliased it to 'emg' - which is quicker to type!\n",
    "\n",
    "# The dir() command will tell us what goodies this module contains:\n",
    "dir(emg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use the **analyse_file_list** method. This method (aka *function*) takes as parameters a list of raw EMG data files,\n",
    "an experiment configuration file (to tell it how to analyse the raw data) and an SPSS output file name (where it will write an SPSS data frame).\n",
    "\n",
    "It also espects a *callback* function. This lets it update us on its progress as the analysis proceeds. Typically it would print messages to the screen or to a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Analysing file: \n",
      "./data/P7.mat\n",
      "\n",
      "Isi: 1.0 ms\n",
      "\n",
      "Interval set expressed in ms: \n",
      "[{'IntervalList': [[-500, 0], [1000, 1500], [1500, 2000]], 'Label': '500'}]\n",
      "\n",
      "Interval set expressed in samples: \n",
      "[{'IntervalList': [[-500, 0], [1000, 1500], [1500, 2000]], 'Label': '500'}]\n",
      "\n",
      "Edge detecting marker channel: 3.\n",
      "Edge detecting marker channel: 4.\n",
      "Edge detecting marker channel: 5.\n",
      "Edge detecting marker channel: 6.\n",
      "Edge detecting marker channel: 7.\n",
      "Edge detecting marker channel: 8.\n",
      "Edge detecting marker channel: 9.\n",
      "\n",
      "Determining event codes from edge set.\n",
      "\n",
      "Unique codes determined from edge set:\n",
      "{64, 1, 32, 2, 4, 8, 16}\n",
      "\n",
      "\n",
      "Codes to be analysed:\n",
      "[1, 2, 4, 8, 16, 32, 64]\n",
      "\n",
      "Code: 64, Label: bat_, N: 20\n",
      "['7.0',\n",
      " '24.5',\n",
      " '30.3',\n",
      " '36.4',\n",
      " '73.0',\n",
      " '185.9',\n",
      " '259.7',\n",
      " '284.1',\n",
      " '303.3',\n",
      " '309.5',\n",
      " '322.3',\n",
      " '364.3',\n",
      " '394.6',\n",
      " '483.0',\n",
      " '538.5',\n",
      " '569.9',\n",
      " '613.6',\n",
      " '650.8',\n",
      " '663.2',\n",
      " '743.8']\n",
      "Code: 1, Label: cat_, N: 10\n",
      "['67.1',\n",
      " '92.1',\n",
      " '129.3',\n",
      " '135.8',\n",
      " '142.2',\n",
      " '346.7',\n",
      " '407.3',\n",
      " '476.9',\n",
      " '687.8',\n",
      " '731.6']\n",
      "Code: 32, Label: mat_, N: 20\n",
      "['12.8',\n",
      " '48.6',\n",
      " '79.2',\n",
      " '160.8',\n",
      " '173.2',\n",
      " '197.8',\n",
      " '241.3',\n",
      " '297.0',\n",
      " '334.1',\n",
      " '340.4',\n",
      " '420.1',\n",
      " '445.5',\n",
      " '464.0',\n",
      " '525.5',\n",
      " '544.8',\n",
      " '638.3',\n",
      " '675.7',\n",
      " '712.9',\n",
      " '725.2',\n",
      " '737.5']\n",
      "Code: 2, Label: dog_, N: 10\n",
      "['19.3',\n",
      " '42.7',\n",
      " '179.9',\n",
      " '191.7',\n",
      " '217.2',\n",
      " '247.8',\n",
      " '352.6',\n",
      " '507.4',\n",
      " '513.5',\n",
      " '520.1']\n",
      "Code: 4, Label: blue_, N: 20\n",
      "['54.7',\n",
      " '60.8',\n",
      " '110.4',\n",
      " '210.9',\n",
      " '222.6',\n",
      " '253.8',\n",
      " '370.5',\n",
      " '426.5',\n",
      " '432.7',\n",
      " '439.3',\n",
      " '457.6',\n",
      " '489.4',\n",
      " '495.4',\n",
      " '531.8',\n",
      " '556.9',\n",
      " '576.1',\n",
      " '588.8',\n",
      " '620.0',\n",
      " '656.9',\n",
      " '706.7']\n",
      "Code: 8, Label: red_, N: 20\n",
      "['98.3',\n",
      " '104.3',\n",
      " '122.9',\n",
      " '148.5',\n",
      " '154.2',\n",
      " '167.0',\n",
      " '228.4',\n",
      " '234.8',\n",
      " '271.9',\n",
      " '278.3',\n",
      " '316.1',\n",
      " '376.4',\n",
      " '451.7',\n",
      " '470.6',\n",
      " '501.4',\n",
      " '550.7',\n",
      " '582.4',\n",
      " '607.4',\n",
      " '694.3',\n",
      " '699.9']\n",
      "Code: 16, Label: hat_, N: 20\n",
      "['85.7',\n",
      " '116.6',\n",
      " '204.6',\n",
      " '266.1',\n",
      " '290.5',\n",
      " '328.4',\n",
      " '358.2',\n",
      " '382.4',\n",
      " '388.5',\n",
      " '401.0',\n",
      " '413.7',\n",
      " '563.8',\n",
      " '595.1',\n",
      " '601.5',\n",
      " '625.8',\n",
      " '631.9',\n",
      " '644.8',\n",
      " '669.4',\n",
      " '681.7',\n",
      " '719.1']\n",
      "Emg channels: {1: 'zyg'}\n",
      "\n",
      "\n",
      "Doing interval list: [[-500, 0], [1000, 1500], [1500, 2000]]\n",
      "\n",
      "N data items: 600\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Analysing file: \n",
      "./data/P3.mat\n",
      "\n",
      "Isi: 1.0 ms\n",
      "\n",
      "Interval set expressed in ms: \n",
      "[{'IntervalList': [[-500, 0], [1000, 1500], [1500, 2000]], 'Label': '500'}]\n",
      "\n",
      "Interval set expressed in samples: \n",
      "[{'IntervalList': [[-500, 0], [1000, 1500], [1500, 2000]], 'Label': '500'}]\n",
      "\n",
      "Edge detecting marker channel: 3.\n",
      "Edge detecting marker channel: 4.\n",
      "Edge detecting marker channel: 5.\n",
      "Edge detecting marker channel: 6.\n",
      "Edge detecting marker channel: 7.\n",
      "Edge detecting marker channel: 8.\n",
      "Edge detecting marker channel: 9.\n",
      "\n",
      "Determining event codes from edge set.\n",
      "\n",
      "Unique codes determined from edge set:\n",
      "{32, 64, 1, 2, 4, 8, 16}\n",
      "\n",
      "\n",
      "Codes to be analysed:\n",
      "[1, 2, 4, 8, 16, 32, 64]\n",
      "\n",
      "Code: 32, Label: mat_, N: 20\n",
      "['2.3',\n",
      " '14.5',\n",
      " '109.8',\n",
      " '140.7',\n",
      " '171.2',\n",
      " '220.6',\n",
      " '258.4',\n",
      " '276.5',\n",
      " '301.3',\n",
      " '400.2',\n",
      " '418.6',\n",
      " '466.9',\n",
      " '491.6',\n",
      " '503.9',\n",
      " '578.7',\n",
      " '652.3',\n",
      " '658.8',\n",
      " '696.6',\n",
      " '721.4',\n",
      " '727.8']\n",
      "Code: 64, Label: bat_, N: 20\n",
      "['21.0',\n",
      " '60.0',\n",
      " '97.4',\n",
      " '153.3',\n",
      " '177.2',\n",
      " '183.0',\n",
      " '201.4',\n",
      " '288.9',\n",
      " '326.5',\n",
      " '375.4',\n",
      " '381.7',\n",
      " '424.9',\n",
      " '473.4',\n",
      " '522.8',\n",
      " '572.2',\n",
      " '591.0',\n",
      " '665.1',\n",
      " '703.1',\n",
      " '708.9',\n",
      " '715.0']\n",
      "Code: 1, Label: cat_, N: 10\n",
      "['129.2',\n",
      " '271.0',\n",
      " '332.9',\n",
      " '338.8',\n",
      " '369.6',\n",
      " '443.4',\n",
      " '448.9',\n",
      " '616.3',\n",
      " '671.7',\n",
      " '740.1']\n",
      "Code: 2, Label: dog_, N: 10\n",
      "['134.5',\n",
      " '239.3',\n",
      " '251.8',\n",
      " '264.7',\n",
      " '344.5',\n",
      " '356.8',\n",
      " '394.2',\n",
      " '431.1',\n",
      " '553.4',\n",
      " '622.0']\n",
      "Code: 4, Label: blue_, N: 20\n",
      "['40.5',\n",
      " '66.0',\n",
      " '78.1',\n",
      " '90.5',\n",
      " '159.2',\n",
      " '165.3',\n",
      " '189.2',\n",
      " '350.8',\n",
      " '406.2',\n",
      " '437.0',\n",
      " '479.6',\n",
      " '516.8',\n",
      " '528.5',\n",
      " '540.8',\n",
      " '547.1',\n",
      " '597.5',\n",
      " '610.1',\n",
      " '634.2',\n",
      " '677.9',\n",
      " '733.6']\n",
      "Code: 8, Label: red_, N: 20\n",
      "['27.5',\n",
      " '33.8',\n",
      " '47.0',\n",
      " '116.1',\n",
      " '122.7',\n",
      " '207.9',\n",
      " '214.3',\n",
      " '226.6',\n",
      " '245.6',\n",
      " '295.0',\n",
      " '307.7',\n",
      " '363.0',\n",
      " '454.6',\n",
      " '460.8',\n",
      " '534.4',\n",
      " '566.3',\n",
      " '584.6',\n",
      " '603.8',\n",
      " '640.1',\n",
      " '690.6']\n",
      "Code: 16, Label: hat_, N: 20\n",
      "['8.8',\n",
      " '53.4',\n",
      " '72.2',\n",
      " '84.0',\n",
      " '103.4',\n",
      " '147.2',\n",
      " '195.9',\n",
      " '233.0',\n",
      " '282.9',\n",
      " '314.3',\n",
      " '320.2',\n",
      " '388.3',\n",
      " '412.5',\n",
      " '485.7',\n",
      " '497.8',\n",
      " '510.2',\n",
      " '559.8',\n",
      " '628.2',\n",
      " '646.2',\n",
      " '684.4']\n",
      "Emg channels: {1: 'zyg'}\n",
      "\n",
      "\n",
      "Doing interval list: [[-500, 0], [1000, 1500], [1500, 2000]]\n",
      "\n",
      "N data items: 600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The configuration file is called malc.json and is in a sub-folder called \"config\":\n",
    "config = \"./config/malc.json\"\n",
    "\n",
    "# The list of subject files we are going to analyse are in a sub-folder called \"data\":\n",
    "files = [\"./data/P7.mat\", r\"./data/P3.mat\"]\n",
    "\n",
    "# It was initially intended that the analysis would be done in SPSS so we specify a file to\n",
    "# write SPSS friendly data to:\n",
    "spss_file = \"junk.csv\"\n",
    "\n",
    "# The analysis is complex and it can give feedback on how it is progressing. We will give it a\n",
    "# \"callback\" function to talk to while it grinds through the data. It will just print to the screen\n",
    "# but it could log to a file etc.\n",
    "\n",
    "def log(message):\n",
    "    print(message)\n",
    "\n",
    "# Then we analyse the data!\n",
    "results = emg.analyse_file_list(config_file=config, file_list=files, \n",
    "                                callback=log, output_file=spss_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it hasn't thrown up a whole bunch of error messages so let's check out the [SPSS data frame](test.csv) we (hopefully!) just made.\n",
    "\n",
    "Now we *could* stop there and analyse our results in SPSS, but why? We can do it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# The analyse_file_list() function returns a dictionary with two entries: a list of computer \n",
    "# generated variable names, and a list of lists of data, one list for each file (i.e. participant)\n",
    "# Lets see how long the lists are:\n",
    "\n",
    "print(len(results[\"variables\"]))\n",
    "print(len(results[\"data\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file_name', 'time_date', 'cat_1_b_zyg_500', 'cat_1_t1_zyg_500', 'cat_1_t2_zyg_500', 'cat_1_n1_zyg_500', 'cat_1_n2_zyg_500', 'cat_2_b_zyg_500', 'cat_2_t1_zyg_500', 'cat_2_t2_zyg_500']\n"
     ]
    }
   ],
   "source": [
    "# Lets take a look at the first 10 variable names:\n",
    "print(results[\"variables\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P7.mat', 'Fri Jul 18 11:50:50 2014', '0.0041851329', '0.0056731677', '0.0054752992', '1.3555525924', '1.3082736822', '0.0043770655', '0.0050048084', '0.0043612598']\n"
     ]
    }
   ],
   "source": [
    "# and the first 10 values of the first participant:\n",
    "print(results[\"data\"][0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
      "[55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Let's suppose we want to compare a participant's response to the \"cat\" stimuli with their response\n",
    "# to the \"dog\" stimuli. First we need to extract the column index of the appropriate variable. Let's\n",
    "# use the n1 interval (the one 1000ms after stimulus):\n",
    "\n",
    "cat_indices = [ind for ind, var in enumerate(results[\"variables\"]) if \"cat\" in var and \"n1\" in var]\n",
    "dog_indices = [ind for ind, var in enumerate(results[\"variables\"]) if \"dog\" in var and \"n1\" in var]\n",
    "print(cat_indices)\n",
    "print(dog_indices)\n",
    "print(len(cat_indices))\n",
    "print(len(dog_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3555525924, 1.1434163791, 1.2755485926, 1.1310243245, 1.3343129223]\n",
      "[1.1006869571, 1.2335782461, 0.965395735, 0.9835172596, 1.1659058388]\n"
     ]
    }
   ],
   "source": [
    "# Now we extract the actual normalised EMG values for our two stimulus types for our first participant:\n",
    "\n",
    "cat_data = [float(results[\"data\"][0] [index]) for index in cat_indices]\n",
    "dog_data = [float(results[\"data\"][0] [index]) for index in dog_indices]\n",
    "\n",
    "print(cat_data[0:5])\n",
    "print(dog_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easy peasy! Let's plot them. First we need the plot package:\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# And we need this bit of magic to tell Jupyter to embed the plots in the notebook (the default is \n",
    "# to create a separate window each time)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7610bb0>,\n",
       " <matplotlib.lines.Line2D at 0x7610cb0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x757a870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(10), cat_data, 'ro', dog_data, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat:  DescribeResult(nobs=10, minmax=(1.0442668857999999, 1.3555525924), mean=1.2118684620500002, variance=0.009153526186521703, skewness=-0.07715694003386762, kurtosis=-0.7500190954450394)\n",
      "\n",
      "Dog:  DescribeResult(nobs=10, minmax=(0.92273431689999996, 1.2335782461), mean=1.0211510261599999, variance=0.011505912593684777, skewness=1.0144739148855484, kurtosis=-0.46646963710067446)\n"
     ]
    }
   ],
   "source": [
    "# The cat EMG responses (red) look to be greater than the dog EMG responses (blue). \n",
    "# Lets explore the data a bit further. \n",
    "# First we need to import the stats module:\n",
    "from scipy import stats\n",
    "\n",
    "# Get some descriptive stats:\n",
    "print(\"Cat: \", stats.describe(cat_data))\n",
    "print()\n",
    "print(\"Dog: \",stats.describe(dog_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=4.1959580675177328, pvalue=0.00054307319489110871)\n"
     ]
    }
   ],
   "source": [
    "# Ok, let's do a t-test:\n",
    "print( stats.ttest_ind(cat_data, dog_data, equal_var=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.31279741478855239, 0.37886499589020406)\n"
     ]
    }
   ],
   "source": [
    "# I have no reason to expect these to be correlated but out of curiosity let's do a Pearson's R:\n",
    "print( stats.pearsonr(cat_data, dog_data) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of what we have done so far:\n",
    "* Imported around 140MB of raw Biopak EMG data\n",
    "* Detected and sorted stimuli event codes\n",
    "* Analysed each stimulus presentation against its event code and a list of intervals to determine normalised EMG values\n",
    "* Generated 600+ meaningful variable names\n",
    "* Created an SPSS friendly results file\n",
    "* Pulled out two events and plotted them\n",
    "* Explored those events by means of descriptive statistics, a t-test and correlation\n",
    "<h3 style=\"padding-bottom: 5em; padding-top: 3em;\">And we did it in a few lines of Python!</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 style=\"text-align: center;\">I'm bored. What else can it do?</h2>\n",
    "\n",
    "Python is a general purpose language. It's not tied to data analysis or statistics, it can do almost anything.\n",
    "\n",
    "I was wondering how many staff the School of Psychology has. Looking at the staff page there were quite a lot. I'm way too lazy to count them though, so I got Python to do it. Here's how...\n",
    "\n",
    "First we need to download the [psychology staff web page](http://www.massey.ac.nz/massey/learning/departments/school-of-psychology/staff/staff-all.cfm) and get it into a Python variable. To do this we use Python's **urllib** package. This package can download a web page or any other file out on the web given a URL. \n",
    "\n",
    "Next we use another Python package to search the downloaded page and find the HTML elements containing the staff names. This is where it gets a bit weird: the Python package to do this is called **BeautifulSoup** (I think it must be a Monty Python reference - the language is full of them).\n",
    "\n",
    "By using Chrome's developer tools (Ctrl-Shift-I) I found out that staff names are presented as HTML \"span\" elements and have been given a CSS class name of \"pf_short_pname\".\n",
    "\n",
    "So, lets download the page, make soup out of it (Yep, that's what it is called) find the contents of all the \"span\" elements of class \"pf_short_name\":  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prof James Liu\n",
      "Amy Aldridge\n",
      "Dr Siautu Alefaio - Tugia\n",
      "Dr Joanne Allen\n",
      "Prof Fiona Alpass\n",
      "Dr Don Baken\n",
      "Abi Beatson\n",
      "Anita Bellamy\n",
      "Dr Simon Bennett\n",
      "Maria Berrett\n",
      "Dr Denise Blake\n",
      "Dr Heather Buttle\n",
      "Dr Peter Cannon\n",
      "Prof Stuart Carr\n",
      "Prof Kerry Chamberlain\n",
      "Dr Leigh Coombes\n",
      "Shelley Cooper\n",
      "Gillian Craven\n",
      "Natasha De Faria\n",
      "Dr Ian de Terte\n",
      "Dr Aaron Drummond\n",
      "Dr John Fitzgerald\n",
      "Dr Richard Fletcher\n",
      "Candi Fletcher\n",
      "Associate Professor Ross Flett\n",
      "Dr Ruth Gammon\n",
      "Emily Garden\n",
      "Dr Dianne Gardner\n",
      "Jhanitra Gavala\n",
      "Dr Bev Haarhoff\n",
      "Dr Gus Habermann\n",
      "Dr Jocelyn Handy\n",
      "Dr Shane Harvey\n",
      "Dr Lauren Hewitt\n",
      "Dr Stephen Hill\n",
      "Prof Darrin Hodgetts\n",
      "Dr Veronica Hopner\n",
      "Dr Emma Hudson-Doyle\n",
      "Hope Hyslop\n",
      "Associate Professor Sarb Johal\n",
      "Prof David Johnston\n",
      "Dr Sara Joice\n",
      "Harvey Jones\n",
      "Dr Linda Jones\n",
      "Dr Ella Kahu\n",
      "Dr Barbara Kennedy\n",
      "Fiona Kennedy\n",
      "Dr Christine Kenney\n",
      "Lizzy Kent\n",
      "Pita King\n",
      "Katie Knapp\n",
      "Dr Ute Kreplin\n",
      "Steven Langdon\n",
      "Prof Janet Leathem\n",
      "Prof James Liu\n",
      "Malcolm Loudon\n",
      "Prof Antonia Lyons\n",
      "Janet Mak\n",
      "Sarah Malthus\n",
      "Helen McMaster\n",
      "Dr Angela McNaught\n",
      "Associate Professor Paul Merrick\n",
      "Prof Mandy Morgan\n",
      "Dr Tracy Morison\n",
      "Elizabeth Nath\n",
      "Julianne Olsen\n",
      "Anne Ormsby\n",
      "Jethro Pack\n",
      "John Pahina\n",
      "Dr Michael Philipp\n",
      "Dr Rachael Pond\n",
      "Dr Raj Prasanna\n",
      "Melissa Rangiwananga\n",
      "Melanie Robertson\n",
      "Dr Ann Rogerson\n",
      "Annette Ross\n",
      "Dr Kirsty Ross\n",
      "Dr Jane Rovins\n",
      "Judith Russell\n",
      "Renee Seebeck\n",
      "Jacinda Shailer\n",
      "Gail Shirley\n",
      "Caroline Stark\n",
      "Prof Chris Stephens\n",
      "Joanne Stevenson\n",
      "Dr Benita Stiles-Smith\n",
      "Dr Agnes Szabo\n",
      "Dr Tatiana Tairi\n",
      "Dr Ruth Tarrant\n",
      "Dr Natasha Tassell-Matamua\n",
      "Dr Joanne Taylor\n",
      "Cara Thompson\n",
      "Judy Tildesley\n",
      "Hung Ton\n",
      "Associate Professor Keith Tuffin\n",
      "Dr Hukarere Valentine\n",
      "Dr Clifford Van Ommen\n",
      "Imogen Veitch\n",
      "Robyn Vertongen\n",
      "Katie Weastell\n",
      "Dr Matt Williams\n",
      "Dr Mei Wah Williams\n",
      "Carrie Wilson\n",
      "Amanda Young-Hauser\n",
      "\n",
      "N =  104\n"
     ]
    }
   ],
   "source": [
    "# We need to import urllib and BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "# get the Psychology staff web page (in ONE line of Python!)\n",
    "web_page = urllib.request.urlopen('http://www.massey.ac.nz/massey/learning/departments/school-of-psychology/staff/staff-all.cfm')\n",
    "\n",
    "# make soup!\n",
    "soup = BeautifulSoup(web_page, \"lxml\")\n",
    "\n",
    "# find the span elements of CSS class pf_short_name and put them in a list called 'staff':\n",
    "staff = soup.find_all('span', class_ = 'pf_short_pname')\n",
    "\n",
    "# extract the span text (ie persons name) and print it\n",
    "for person in staff:\n",
    "    # print their name\n",
    "    print(person.string)\n",
    "    \n",
    "print(\"\\nN = \", len(staff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massey University (Māori: Te Kunenga ki Pūrehuroa) is a university based in Раlmеrstоn Nоrth, Nеw Zеаlаnd, with significant campuses in Аlbаny and Wellington. Massey University has approximately 35,000 students, 17,000 of whom are extramural or distance-learning students, making it New Zealand's second largest university when not counting international students. Research is undertaken on all three campuses, and more than 3,000 international students from over 100 countries study at the university.\n",
      "Massey University is the only university in New Zealand offering degrees in aviation, dispute resolution, veterinary medicine, and nanoscience. Massey's veterinary school is accredited by the American Veterinary Medical Association and is recognised in the United States, Australia, Canada, and Britain. Its agriculture programme is the highest-ranked in New Zealand, and 19th in Quacquarelli Symonds' (QS) world university subject rankings. Massey's Bachelor of Aviation (Air Transport Pilot) is an internationally recognised and accredited qualification, is the first non-engineering degree to be recognised by the Royal Aeronautical Society (1998), and has ISO9001-2000 accreditation.\n",
      "\n",
      "\n",
      "== Key facts ==\n",
      "From 2008 Annual Report:\n",
      "$374 million operating revenue\n",
      "$57 million external research and contract funding\n",
      "3127 staff (full-time Equivalent)\n",
      "33,905 students (19,432 EFTS)\n",
      "27251 undergraduate students (15,070 EFTS)\n",
      "7212 postgraduate students (3,428 EFTS)\n",
      "1046 doctorate students (934 EFTS)\n",
      "112 doctoral completions\n",
      "3384 Māori students\n",
      "895 Pasiﬁka students\n",
      "2447 students with disabilities\n",
      "2 National Centres of Research Excellence (and numerous University-based Research Centres)\n",
      "Hosts the National Centre for Tertiary Teaching Excellence\n",
      "The University has almost 100 formal academic arrangements with overseas institutions\n",
      "Massey is the 10th largest user of Information and Communications Technology (ICT) in New Zealand\n",
      "\n",
      "\n",
      "== History ==\n",
      "The New Zealand Agricultural College Act of 1926 estab\n"
     ]
    }
   ],
   "source": [
    "# Last but not least, Python can talk to Twitter, Facebook, LinkedIn, Wikipedia, etc.\n",
    "\n",
    "# Load the wikipedia API module \n",
    "import wikipedia\n",
    "\n",
    "# Get the wiki entry for Massey University\n",
    "massey = wikipedia.page(\"Massey University\")\n",
    "\n",
    "# and print some of it to prove it works:\n",
    "print(massey.content[0:2000])\n",
    "\n",
    "# It's that easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "<h2 style=\"text-align: center; padding-top: 5em;\">Concluding Remarks</h2>\n",
    "\n",
    "Twenty first century scientific software is moving away from discrete commercial products like E-Prime/MATLAB/SPSS towards open-source software ecosystems. ** Jupyter ** wraps up Python, R, data manipulation and analysis, typesetting and much more into a live document that can be shared and worked on by collaborators at a distance (using JupyterHub or GitHub).\n",
    "\n",
    "<h4 style=\"text-align: center; color:  #8B6508;\">  I know what you are thinking: \"This is all very well but I can't afford the time to learn this kind of stuff.\"</h4>\n",
    "\n",
    "Perhaps, but if you regularly need to clean, manipulate and transform data can you afford *not* to? Over the years I have seen graduate students and staff spend hours (that could be used learning Python!) noodling around with Excel hacking their data into a form they could analyse: ** when your only tool is a hammer, everything looks like a nail. **\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
